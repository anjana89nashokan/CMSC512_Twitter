{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1ad7ef",
   "metadata": {},
   "source": [
    "#, 'trump2020', 'kag2020', 'kag', 'maga2020', 'MAGA','trump', 'americafirst', '', 'wwg1wga', 'NeverBiden','Storm', 'Sleepy joe', 'Raid','CreepyJoeBiden','Riot', 'Terrorists','','Insurrection']\n",
    "#'trump2020landslide'\n",
    "#'Trumpsters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f804bfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import csv\n",
    "import os\n",
    "start_date = '2020-11-01'\n",
    "end_date = '2021-01-07'\n",
    "tweets_list = []\n",
    "user_nodes = []\n",
    "tweetID = []\n",
    "keyword_count = [0, 0, 0, 0, 0, 0]\n",
    "keyword = [\n",
    "            'stoptheseal', \n",
    "            'sharpiegate', \n",
    "            'riggedelection', \n",
    "            'electionfraud', \n",
    "            'electionmeddling',\n",
    "            'qanon'\n",
    "                ]  \n",
    "\n",
    "#defintion of the tweet objects\n",
    "class tweets_det:\n",
    "    def __init__(self, tweet):\n",
    "        self.tweetID = tweet.id\n",
    "        self.tweetDate = tweet.date\n",
    "        self.userID = tweet.user.id\n",
    "        self.tweetUserName = tweet.user.username \n",
    "        self.tweetContent = tweet.content\n",
    "        self.likeCount = tweet.likeCount\n",
    "        self.retweetCount = tweet.retweetCount\n",
    "        self.follower_id = []      \n",
    "        self.follower_username = []\n",
    "        \n",
    "        self.replycount = tweet.replyCount\n",
    "        self.quoteCount = tweet.quoteCount\n",
    "        \n",
    "class node_user:\n",
    "    def __init__(self, tweet):\n",
    "        self.userID = tweet.user.id\n",
    "        self.username = tweet.user.username\n",
    "        self.followersCount = tweet.user.followersCount\n",
    "        self.retweetCount = tweet.retweetCount  \n",
    "        self.likeCount = tweet.likeCount \n",
    "        \n",
    "        self.replyCount = tweet.replyCount  \n",
    "        self.quoteCount = tweet.quoteCount  \n",
    "        self.tweetID = []\n",
    "        self.keyword = []\n",
    "        self.node_weight = 0\n",
    "        self.tweetCount = 1\n",
    "    def append(tweetID):\n",
    "        self.tweetID.append(tweet.id)\n",
    "    def append(follower_id):\n",
    "        self.follower_id.append(followerID)\n",
    "    def append(follower_username):\n",
    "        self.follower_username(follower_username)\n",
    "    def append(keyword):\n",
    "        self.keyword(keyword)\n",
    "        \n",
    "# The function to read tweets using snscrape and create an object for each tweet\n",
    "def read_tweets():\n",
    "    maxTweets = 30000 \n",
    "    csvFileTweets = open('01_Tweets_List_Latest.csv', 'a', newline='', encoding='utf8')\n",
    "    csvWriterTweets = csv.writer(csvFileTweets)\n",
    "    csvWriterTweets.writerow(['Tweet id','Tweet date','UserID', 'User Name', 'tweet Content', 'Reply Count', 'Tweet Retweet count', 'Like Count', 'Quote Count'])         \n",
    "    \n",
    "    csvFile_Keyword = open('05_Tweets_Keyword_Count.csv', 'a', newline='', encoding='utf8')\n",
    "    csvWriter_Keyword = csv.writer(csvFile_Keyword) \n",
    "    csvWriter_Keyword.writerow(['Keyword','Weight'])\n",
    "                               \n",
    "    for j in range(len(keyword)):\n",
    "        print (keyword[j]) \n",
    "        for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{keyword[j]} + since:{start_date} until:{end_date} -filter:links -filter:replies').get_items()):   \n",
    "            if i > maxTweets:  \n",
    "                break  \n",
    "            if (tweet.id not in tweetID):\n",
    "                csvWriterTweets.writerow([int(tweet.id), tweet.date, tweet.user.id, tweet.user.username, tweet.content, tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount])\n",
    "                tweetID.append(tweet.id)\n",
    "                tweets_list.append(tweets_det(tweet))\n",
    "                if (len(user_nodes) == 0):\n",
    "                    user_nodes.append(node_user(tweet))\n",
    "                    user_nodes[0].tweetID.append(tweet.id)\n",
    "                    user_nodes[0].keyword.append(keyword)\n",
    "                    keyword_count[j] = keyword_count[j] + 1\n",
    "                    user_nodes[0].node_weight += (tweet.retweetCount + tweet.likeCount)\n",
    "                else:\n",
    "                    k, found=0, 0  \n",
    "                    while(k<len(user_nodes) and (found == 0)):\n",
    "                        if (user_nodes[k].userID==tweet.user.id):\n",
    "                            found = 1\n",
    "                            user_nodes[k].replyCount += tweet.replyCount\n",
    "                            user_nodes[k].retweetCount += tweet.retweetCount\n",
    "                            user_nodes[k].likeCount += tweet.likeCount\n",
    "                            user_nodes[k].quoteCount += tweet.quoteCount\n",
    "                            user_nodes[k].tweetID.append(tweet.id)\n",
    "                            user_nodes[k].keyword.append(keyword)\n",
    "                            keyword_count[j] = keyword_count[j] + 1\n",
    "                            user_nodes[k].node_weight += (tweet.retweetCount + tweet.likeCount)\n",
    "                            user_nodes[k].tweetCount +=1\n",
    "                        k+=1\n",
    "                    if (found ==0 and k == len(user_nodes)):\n",
    "                        user_nodes.append(node_user(tweet))\n",
    "                        user_nodes[k].tweetID.append(tweet.id)\n",
    "                        user_nodes[k].keyword.append(keyword)\n",
    "                        keyword_count[j] = keyword_count[j] + 1\n",
    "                        user_nodes[k].node_weight += (tweet.retweetCount + tweet.likeCount)\n",
    "            else:\n",
    "                print(\"Duplicate Tweet found\")                    \n",
    "        csvWriter_Keyword.writerow([keyword[j], int(keyword_count[j])])\n",
    "    csvFileTweets.close()\n",
    "    csvFile_Keyword.close()\n",
    "\n",
    "if __name__==\"__main__\":  \n",
    "    read_tweets()\n",
    "    print(\"######Reading tweets Done\")\n",
    "    print(\"######Creating user nodes files in progress\")\n",
    "    csvFile_user_node_graph = open('06_user_node_graph.csv', 'a', newline='', encoding='utf8')\n",
    "    csvWriter_User = csv.writer(csvFile_user_node_graph) \n",
    "    csvWriter_User.writerow(['Label','Node_weight']) \n",
    "        \n",
    "    user_nodes_files = '02_User_Nodes_000_0.csv'\n",
    "    csvFile9 = open(user_nodes_files, 'a', newline='', encoding='utf8')\n",
    "    csvWriter9 = csv.writer(csvFile9)\n",
    "    csvWriter9.writerow(['User ID', 'User Name', 'Node_weight', 'Reply Count', 'Retweet count', 'Like Count', 'Quote Count', 'Followers Count', 'Keywords','Tweet Count']) \n",
    "\n",
    "    m = 0\n",
    "    for i in range (len(user_nodes)):\n",
    "        csvWriter_User.writerow([user_nodes[i].username, int(user_nodes[i].node_weight)])\n",
    "        csvWriter9.writerow([int(user_nodes[i].userID), user_nodes[i].username, int(user_nodes[i].node_weight), int(user_nodes[i].replyCount), int(user_nodes[i].retweetCount), int(user_nodes[i].likeCount), int(user_nodes[i].quoteCount), int(user_nodes[i].followersCount), user_nodes[i].keyword, int(user_nodes[i].tweetCount)]) \n",
    "        if ((i+1)%1000==0):\n",
    "            m+=1\n",
    "            csvFile9.close()\n",
    "            user_nodes_files = '02_User_Nodes_000_'+str(m)+'.csv'\n",
    "            print(\"user_nodes_files: \", user_nodes_files)\n",
    "            csvFile9 = open(user_nodes_files, 'a', newline='', encoding='utf8')\n",
    "            csvWriter9 = csv.writer(csvFile9)\n",
    "            csvWriter9.writerow(['User ID', 'User Name', 'Node_weight', 'Reply Count', 'Retweet count', 'Like Count', 'Quote Count', 'Followers Count', 'Keywords', 'Tweet Count']) \n",
    "    csvFile_user_node_graph.close()\n",
    "    print(\"User node input file for creating graph- containing username and node_weight created.\")\n",
    "    csvFile9.close()    \n",
    "    print(len(user_nodes), \"#users added to file.\")\n",
    "    print(\".....Keyword counts....\")\n",
    "    csvFileKeyword = open('00_Keyword_Count.csv', 'a', newline='', encoding='utf8')\n",
    "    csvWriterKeywords = csv.writer(csvFileKeyword)\n",
    "    csvWriterKeywords.writerow(['Keyword', 'Keyword_Count'])\n",
    "    for x in range(len(keyword)):\n",
    "        csvWriterKeywords.writerow([keyword[x], int(keyword_count[x])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c638367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the user data from file to object while collecting followers data \n",
    "#DO NOT FORGET REPLACE YOUR FILE NAME HERE\n",
    "userfilename = '02_User_Nodes_000_44.csv'\n",
    "from csv import DictReader\n",
    "class node_user:\n",
    "    def __init__(self, user_ID, user_name, node_weight, replyCount, retweetCount, likeCount, quoteCount, followersCount):\n",
    "        self.userID = user_ID\n",
    "        self.username = user_name\n",
    "        self.replyCount = replyCount  \n",
    "        self.retweetCount = retweetCount  \n",
    "        self.likeCount = likeCount \n",
    "        self.quoteCount = quoteCount  \n",
    "        self.followersCount = followersCount\n",
    "        self.follower_id = []  \n",
    "        self.follower_username = []\n",
    "        self.tweetID = []\n",
    "        self.node_weight = 0\n",
    "    def append(tweetID):\n",
    "        self.tweetID.append(tweet_id)\n",
    "    def append(follower_id):\n",
    "        self.follower_id.append(followerID)\n",
    "    def append(follower_username):\n",
    "        self.follower_username(follower_username)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    user_nodes_file = open(userfilename , 'r') #\n",
    "    user_nodes_from = DictReader(user_nodes_file)\n",
    "\n",
    "    user_nodes = []\n",
    "    print(\"Entering for loop\")\n",
    "\n",
    "    for user in user_nodes_from:\n",
    "        user_ID = user['User ID']      \n",
    "        user_name = user['User Name']\n",
    "        replyCount = int(user['Reply Count'])\n",
    "        retweetCount = int(user['Retweet count'])\n",
    "        likeCount = int(user['Like Count'])\n",
    "        quoteCount = int(user['Quote Count'])\n",
    "        followersCount = int(user['Followers Count'])\n",
    "        node_weight= int(user['Node_weight'])\n",
    "        user_nodes.append(node_user(user_ID, user_name, node_weight, replyCount, retweetCount, likeCount, quoteCount, followersCount))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the followers Data in batches\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timezone   \n",
    "end_date = '2021-01-07'\n",
    "csvFile3 = open('03_User_Followers_000_01.csv', 'a', newline='', encoding='utf8')\n",
    "csvWriter3 = csv.writer(csvFile3)\n",
    "csvFile4 = open('04_User_data_for_graph_01.csv', 'a', newline='', encoding='utf8')\n",
    "csvWriter4 = csv.writer(csvFile4)\n",
    "#csvWriter4.writerow(['Source', 'Target', 'Type']) \n",
    "#csvWriter3.writerow(['userID', 'username', 'followersCount', 'likeCount', 'retweetCount', 'follower_id_list', 'follower_username_list'])\n",
    "\n",
    "def strp_time(created_at):\n",
    "    created_at = datetime.strptime(created_at, '%Y-%m-%dT%H:%M:%S.%fZ').replace(\n",
    "            tzinfo=timezone.utc).astimezone(tz=None).strftime('%Y-%m-%d')\n",
    "    return(created_at)\n",
    "\n",
    "from TwitterAPI import TwitterAPI, TwitterPager, HydrateType\n",
    "\n",
    "consumer_key        = \"TcS7ZvWZjZLkNCMr9vzzjAAwb\"\n",
    "consumer_secret     = \"FjXl1Ys2HeL6BqsQpiU813lGRYGDqNOWRekzc9lEmcZX2PvHD5\"\n",
    "access_token        = \"1486782696579813378-Qsv8jzODeZXGl7yrjG01PCH6FWhFXL\"\n",
    "access_token_secret = \"91vSsGRNWulHQqcQdlqI1M401vVqO4ux6tiPFR0y8TN2Z\"\n",
    "\n",
    "client = TwitterAPI(consumer_key, consumer_secret, access_token, access_token_secret, api_version=\"2\")\n",
    "followers = []\n",
    "follower_createdat = []\n",
    "print(\"The number of users in the file : \",len(user_nodes))\n",
    "counter = 0\n",
    "sleep = 100\n",
    "\n",
    "for i in range(len(user_nodes)):\n",
    "#for i in range(54, 55):\n",
    "    print(\"User_name : \", user_nodes[i].username)\n",
    "    params = {\n",
    "            \"max_results\": 200,\n",
    "            \"user.fields\": \"id,username,created_at\",\n",
    "        }\n",
    "    print(\"USer_ID in the current loop: \", user_nodes[i].userID)\n",
    "    pager = TwitterPager(client, f\"users/:{user_nodes[i].userID}/followers\", params,hydrate_type=HydrateType.APPEND)    \n",
    "    follower_id = []\n",
    "    follower_username = []\n",
    "    for followers in pager.get_iterator(wait=sleep, new_tweets=False):\n",
    "        counter+=1\n",
    "        if (strp_time(followers['created_at'])<=end_date):\n",
    "            follower_id.append(followers['id'])\n",
    "            follower_username.append(followers['username'])\n",
    "        if (counter%6000 == 0):\n",
    "            sleep = sleep+90\n",
    "    \n",
    "    for j in range(len(follower_id)):\n",
    "        user_nodes[i].follower_id.append(follower_id[j])            \n",
    "        user_nodes[i].follower_username.append(follower_username[j]) \n",
    "        csvWriter4.writerow([user_nodes[i].username, follower_username[j], 'Directed']) \n",
    "    print(len(follower_id), \"no. of followers added to file 4 - graph data- for user- \", user_nodes[i].username)\n",
    "    csvWriter3.writerow([user_nodes[i].userID, user_nodes[i].username, user_nodes[i].followersCount, user_nodes[i].likeCount, user_nodes[i].retweetCount, follower_id, follower_username])\n",
    "    print(\"Data written to file 3\")\n",
    "csvFile3.close()\n",
    "csvFile4.close() \n",
    "print(\"Done \")\n",
    "print(\"Reading followers of all users Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d13284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the 1000 + 1000 followers of a user \n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timezone   \n",
    "end_date = '2021-01-07'\n",
    "\n",
    "csvFile4 = open('04_User_data_for_graph_top_10_Part1.csv', 'a', newline='', encoding='utf8')\n",
    "csvWriter4 = csv.writer(csvFile4)\n",
    "#csvWriter4.writerow(['Source', 'Target', 'Type']) \n",
    "csvFile3 = open('04_User_data_for_graph_top_10_Part2.csv', 'a', newline='', encoding='utf8')\n",
    "csvWriter3 = csv.writer(csvFile3)\n",
    "#csvWriter3.writerow(['Source', 'Target', 'Type']) \n",
    "\n",
    "def strp_time(created_at):\n",
    "    created_at = datetime.strptime(created_at, '%Y-%m-%dT%H:%M:%S.%fZ').replace(\n",
    "            tzinfo=timezone.utc).astimezone(tz=None).strftime('%Y-%m-%d')\n",
    "    return(created_at)\n",
    "\n",
    "from TwitterAPI import TwitterAPI, TwitterPager, HydrateType\n",
    "\n",
    "consumer_key        = \"TcS7ZvWZjZLkNCMr9vzzjAAwb\"\n",
    "consumer_secret     = \"FjXl1Ys2HeL6BqsQpiU813lGRYGDqNOWRekzc9lEmcZX2PvHD5\"\n",
    "access_token        = \"1486782696579813378-Qsv8jzODeZXGl7yrjG01PCH6FWhFXL\"\n",
    "access_token_secret = \"91vSsGRNWulHQqcQdlqI1M401vVqO4ux6tiPFR0y8TN2Z\"\n",
    "\n",
    "client = TwitterAPI(consumer_key, consumer_secret, access_token, access_token_secret, api_version=\"2\")\n",
    "username = 'BernardKerik'\n",
    "userID = 25837289\n",
    "follower_createdat = []\n",
    "counter = 0\n",
    "sleep = 100\n",
    "\n",
    "params = {\n",
    "            \"max_results\": 200,\n",
    "            \"user.fields\": \"id,username,created_at\",\n",
    "        }\n",
    "pager = TwitterPager(client, f\"users/:{userID}/followers\", params,hydrate_type=HydrateType.APPEND)    \n",
    "print(\"Reading followers data\")\n",
    "for followers in pager.get_iterator(wait=sleep, new_tweets=False):\n",
    "    \n",
    "    if (strp_time(followers['created_at'])<=end_date):\n",
    "        counter+=1\n",
    "        if (counter<=1000):\n",
    "            csvWriter4.writerow([username, followers['username'], 'Directed'])\n",
    "        else:\n",
    "            if(counter<=2000):\n",
    "                csvWriter3.writerow([username, followers['username'], 'Directed'])\n",
    "    if (counter==2000):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #if (counter%6000 == 0):\n",
    "        #sleep = sleep+90 \n",
    "\n",
    "print( \"1000 followers added to file 3 and 4 - graph data- for user- \", username)\n",
    "csvFile4.close() \n",
    "csvFile4.close() \n",
    "print(\"Done \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69959893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
